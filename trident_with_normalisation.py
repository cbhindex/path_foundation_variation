#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Aug 12 23:17:10 2025

@author: Dr Binghao Chai
@institute: University College London (UCL)

The propose of this script is to act as a bridge and apply colour normalisation 
before patch embedding extraction using Trident, without reinventing the wheels
and/or break the current Trident package.

This script reads WSIs and patch coordinate (h5 files, generated by Trident), 
applies GPU‑accelerated colour normalisation (Vahadane, Macenko or Reinhard) 
using torch‑staintools, then generates patch embeddings using a Trident patch 
encoder (e.g. UNI‑v1/v2 etc). It saves features and coordinates in the same .h5 
format that Trident uses.

Key features:
1. Patch loading using cuCIM instead of OpenSlide, so patches can be directly 
load into GPU memory which resolves the I/O bottleneck.
2. Fit the normaliser once on a target image and reuse it for all tiles to accelarate.
3. Batching via DataLoader; all heavy work remains on the GPU.

Example usage:
python bridge_trident_normalization.py \
    --wsi_dir /path/to/wsis \
    --coords_dir /path/to/coords \
    --out_dir /path/to/output \
    --target_img_path /path/to/target_image.tif \
    --encoder_name uni_v2 \
    --norm_method vahadane \
    --batch_size 128 \
    --gpu 0 \
    --mag 20

Parameters
----------
wsi_dir: str
    Directory containing WSIs.
    
coords_dir: str
    Directory with *_patches.h5 coordinate files.

out_dir: str
    Directory to save output .h5 files.
    
target_img_path: str
    Path to the target image for fitting the colour normaliser.
    
encoder_name: str
    Trident patch encoder name (e.g. uni_v1, uni_v2, conch_v1).
    
norm_method: str
    Colour normalisation method, choose from "vahadane", "macenko", and "reinhard".

batch_size: int
    Batch size for processing patches.
    
gpu: int
    CUDA device index to use (0, 1, ...).
    
mag: int
    Desired magnification (e.g. 20 for 20×).

custom_list_of_wsis: str
    Optional CSV path with header 'wsi' and rows like 'XXX.svs'. Only slides 
    listed here will be considered.
    
"""

import os
import argparse
import csv
from tqdm import tqdm

import numpy as np
from PIL import Image
import math

import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader

# Trident imports
from trident.patch_encoder_models.load import encoder_factory
from trident.IO import read_coords, save_h5

from torch_staintools.normalizer import NormalizerBuilder

from cucim import CuImage
import cupy

# Construct a cuCIM-based patch loader that returns torch tensors on GPU
def make_patch_loader(
        slide_path: str, patch_size: int, device: torch.device, level: int):

    cuimg = CuImage(slide_path)

    def load_xy(x: int, y: int) -> torch.Tensor:
        
        region = cuimg.read_region(
            location=(int(x), int(y)), 
            size=(patch_size, patch_size), 
            level=level)
        
        cp_arr = cupy.asarray(region) # H x W x C (uint8)
        tensor = torch.as_tensor(cp_arr, device=device) # H x W x C
        tensor = tensor.permute(2, 0, 1).float() / 255.0 # C x H x W in [0,1]
        
        return tensor

    return load_xy

# Define a DataClass
class PatchDataset(Dataset):
    """
    Dataset that yields (patch_tensor, (x, y)) pairs for a single slide.
    Loader returns GPU tensors (C,H,W) in [0,1].
    """
    def __init__(self, loader, coords: np.ndarray):
        super().__init__()
        self.loader = loader
        self.coords = coords

    def __len__(self) -> int:
        return len(self.coords)

    def __getitem__(self, idx: int):
        x, y = self.coords[idx]
        patch_tensor = self.loader(x, y)
        return patch_tensor, (int(x), int(y))

# make collation return coords as (N, 2) tensor instead of (xs, ys) tuple
def _collate_batch(batch):
    patches, coords = zip(*batch) # patches: tuple(Tensor), coords: tuple((x,y),...)
    patches = torch.stack(patches, dim=0) # (N, C, H, W)
    coords = torch.tensor(coords, dtype=torch.int32) # (N, 2) on CPU
    return patches, coords

# Define a function to extract patches (cuCIM), apply colour normalisation (GPU), 
# embedding generation (GPU), and then save to .h5 that aligns with Trident
def process_slide(
        slide_path: str,
        coords_path: str,
        out_path: str,
        normalizer: NormalizerBuilder,
        patch_encoder: torch.nn.Module,
        post_normalize: transforms.Normalize,
        batch_size: int,
        device: torch.device,
        level: int) -> None:

    attrs, coords = read_coords(coords_path)
    patch_size = attrs.get('patch_size')
    if patch_size is None:
        raise KeyError(f"patch_size missing in {coords_path}")

    loader = make_patch_loader(slide_path, patch_size, device, level)
    dataset = PatchDataset(loader, coords)
    dataloader = DataLoader(
        dataset, batch_size=batch_size, 
        shuffle=False, num_workers=0, 
        pin_memory=False, collate_fn=_collate_batch
        )

    features_list = []
    coords_list = []

    slide_name = os.path.basename(slide_path)

    for patches, batch_coords in tqdm(dataloader, desc=f"Processing {slide_name}"):
        # patches already on GPU; .to(device) is no-op but harmless
        patches = patches.to(device, non_blocking=True)

        # robust normalisation with per-tile fallback on error 
        try:
            batch_norm = normalizer(patches)  # fast path: whole batch
            ok_coords = batch_coords  # (N,2) tensor
        except Exception:
            # Fallback: try each tile; keep only successful ones
            kept_norm = []
            kept_coords = []
            for i in range(patches.size(0)):
                try:
                    ni = normalizer(patches[i:i+1])  # keep BCHW
                    kept_norm.append(ni)
                    kept_coords.append(batch_coords[i:i+1])
                except Exception:
                    # skip this tile — do not add its coords/features
                    continue
            if not kept_norm:
                # whole batch failed; skip to next batch
                continue
            batch_norm = torch.cat(kept_norm, dim=0) # (K,C,H,W)
            ok_coords = torch.cat(kept_coords, dim=0) # (K,2)

        # encoder mean/std normalisation
        batch_norm = post_normalize(batch_norm)

        # embed only the surviving tiles
        with torch.inference_mode():
            batch_features = patch_encoder(batch_norm) # (K, D)

        features_list.append(batch_features.detach().cpu().numpy())
        coords_list.append(ok_coords.numpy()) # (K,2)

    if not features_list:
        # if nothing survived, then create empty H5 with coords attrs to signal 
        # processing attempted
        os.makedirs(os.path.dirname(out_path), exist_ok=True)
        save_h5(
            save_path=out_path,
            assets={'features': np.empty((0, 1), dtype=np.float32),  # placeholder
                    'coords': np.empty((0, 2), dtype=np.int64)},
            attributes={'features': {'name': os.path.splitext(os.path.basename(slide_path))[0],
                                     'encoder': getattr(patch_encoder, 'enc_name', None)},
                        'coords': attrs},
            mode='w',
        )
        return

    features = np.concatenate(features_list, axis=0) # (total_kept, D)
    coords_array = np.concatenate(coords_list, axis=0).astype(np.int64) # (total_kept, 2)

    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    model_name = getattr(patch_encoder, 'enc_name', None)

    save_h5(
        save_path=out_path,
        assets={'features': features, 'coords': coords_array},
        attributes={
            'features': {
                'name': os.path.splitext(os.path.basename(slide_path))[0],
                'encoder': model_name
            },
            'coords': attrs,
        },
        mode='w',
    )

# Define other helper functions
def _load_wsi_list_from_csv(csv_path: str):
    """Read a CSV with header 'wsi' and return a list of filenames (e.g., 'XXX.svs')."""
    wsis = []
    with open(csv_path, newline='') as f:
        reader = csv.DictReader(f)
        if 'wsi' not in reader.fieldnames:
            raise ValueError(f"CSV {csv_path} must have a header named 'wsi'")
        for row in reader:
            name = (row.get('wsi') or '').strip()
            if name:
                wsis.append(name)
    return wsis

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Colour normalisation and embedding generationg with Trident."
    )
    
    parser.add_argument("--wsi_dir", type=str, required=True,
                        help="Directory containing WSIs.")
    parser.add_argument("--coords_dir", type=str, required=True,
                        help="Directory with *_patches.h5 coordinate files.")
    parser.add_argument("--out_dir", type=str, required=True,
                        help="Directory to save output .h5 files.")
    parser.add_argument("--target_img_path", type=str, required=True,
                        help="Path to the target image for fitting the colour normaliser.")
    parser.add_argument("--encoder_name", type=str, default="uni_v2",
                        help="Trident patch encoder name (e.g. uni_v1, uni_v2, conch_v1).")
    parser.add_argument("--norm_method", type=str, default="macenko",
                        choices=["vahadane", "macenko", "reinhard"],
                        help="Colour normalisation method.")
    parser.add_argument("--batch_size", type=int, default=128,
                        help="Batch size for processing patches.")
    parser.add_argument("--gpu", type=int, default=0,
                        help="CUDA device index to use (0, 1, ...).")
    parser.add_argument("--mag", type=int, default=20,
                        help="Desired magnification (e.g. 20 for 20×).")
    parser.add_argument("--custom_list_of_wsis", type=str, default=None,
                        help="Optional CSV path with header 'wsi' and rows like \
                            'XXX.svs', only slides listed here will be considered.")
                            
    args = parser.parse_args()

    # Device and level from magnification
    device = torch.device(f"cuda:{args.gpu}" if torch.cuda.is_available() else "cpu")
    scan_power = 40.0
    desired_mag = float(max(args.mag, 1))
    level = 0 if desired_mag >= scan_power else max(0, int(round(math.log(scan_power / desired_mag, 2))))

    # Fit colour normaliser on target image
    target_image = Image.open(args.target_img_path).convert("RGB")
    target_tensor = transforms.ToTensor()(target_image).unsqueeze(0).to(device)
    normalizer = NormalizerBuilder.build(args.norm_method, concentration_method="ls").to(device)
    normalizer.fit(target_tensor)

    # Trident patch encoder
    patch_encoder = encoder_factory(args.encoder_name).to(device).eval()

    # Pull mean/std from encoder eval transforms
    normalize_transforms = [t for t in patch_encoder.eval_transforms.transforms
                            if isinstance(t, transforms.Normalize)]
    if normalize_transforms:
        mean = normalize_transforms[0].mean
        std = normalize_transforms[0].std
    else:
        mean = torch.tensor([0.485, 0.456, 0.406])
        std = torch.tensor([0.229, 0.224, 0.225])
    post_normalize = transforms.Normalize(mean=mean, std=std)

    os.makedirs(args.out_dir, exist_ok=True)

    # build candidate WSI list
    allowed_exts = ('.svs', '.tif', '.tiff', '.ndpi', '.mrxs')

    if args.custom_list_of_wsis:
        # 1) only process WSIs listed in CSV
        csv_wsis = _load_wsi_list_from_csv(args.custom_list_of_wsis)
        candidate_wsis = sorted(csv_wsis)
    else:
        # default: all files in wsi_dir with allowed extensions
        candidate_wsis = sorted([f for f in os.listdir(args.wsi_dir)
                                 if f.lower().endswith(allowed_exts)])

    missing_wsi = [] # 3) listed in CSV but file not found in wsi_dir
    missing_coords = [] # 4) WSI exists but *_patches.h5 missing in coords_dir

    # iterate and filter or skips
    for filename in candidate_wsis:
        # must be a supported image extension
        if not filename.lower().endswith(allowed_exts):
            continue

        slide_path = os.path.join(args.wsi_dir, filename)
        basename, _ = os.path.splitext(filename)
        coords_file = os.path.join(args.coords_dir, f"{basename}_patches.h5")
        out_file = os.path.join(args.out_dir, f"{basename}.h5")

        # 3) if WSI file missing in wsi_dir, remember and skip
        if not os.path.isfile(slide_path):
            missing_wsi.append(filename)
            continue

        # 2) if output already exists, skip
        if os.path.isfile(out_file):
            continue

        # 4) if coords missing, remember and skip
        if not os.path.isfile(coords_file):
            missing_coords.append(filename)
            continue

        # process this slide
        process_slide(
            slide_path=slide_path,
            coords_path=coords_file,
            out_path=out_file,
            normalizer=normalizer,
            patch_encoder=patch_encoder,
            post_normalize=post_normalize,
            batch_size=args.batch_size,
            device=device,
            level=level,
        )

    # output the summary of skipped items 
    if missing_wsi:
        print("\n[SKIPPED - MISSING WSI in --wsi_dir]")
        for name in missing_wsi:
            print("  -", name)

    if missing_coords:
        print("\n[SKIPPED - MISSING COORDS in --coords_dir]")
        for name in missing_coords:
            print("  -", name)
            